# -*- coding: utf-8 -*-
"""TextClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u0B2uagjtYQd-zegw8m7RvqVlPlKpw1Z

# **Imports**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import lightgbm as lgb
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score, recall_score, f1_score, precision_recall_fscore_support
from sklearn.model_selection import GridSearchCV

"""# **Data Loading and Exploration**


"""

categories = None
newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))
newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))

df_train = pd.DataFrame({'text': newsgroups_train.data, 'target': newsgroups_train.target})
df_test = pd.DataFrame({'text': newsgroups_test.data, 'target': newsgroups_test.target})

print("Number of Training Samples:", len(df_train))
print("Number of Test Samples:", len(df_test))
print("Number of Categories:", len(newsgroups_train.target_names))

df_train.head()

df_train['target'].value_counts()

for idx, category in enumerate(newsgroups_train.target_names):
    print(f"{idx}: {category}")

"""# **Clean Text**"""

import re
import nltk

nltk.download('stopwords')
from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'\W+', ' ', text)
    words = text.split()
    words = [word for word in words if word not in stop_words]
    return ' '.join(words)

df_train['cleaned_text'] = df_train['text'].apply(clean_text)
df_test['cleaned_text'] = df_test['text'].apply(clean_text)

"""# **Preprocessing and TF-IDF Vectorization**


"""

tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)

X_train_tfidf = tfidf_vectorizer.fit_transform(df_train['cleaned_text'])
X_test_tfidf = tfidf_vectorizer.transform(df_test['cleaned_text'])

y_train = df_train['target']
y_test = df_test['target']

print("Shape of TF-IDF matrix:", X_train_tfidf.shape)

"""# **Model Training and Evaluation Functions**

"""

# Define training functions
def train_naive_bayes(X_train, y_train):
    nb_model = MultinomialNB()
    nb_model.fit(X_train, y_train)
    return nb_model

def train_random_forest(X_train, y_train):
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    return rf_model

def train_xgboost(X_train, y_train):
    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
    xgb_model.fit(X_train, y_train)
    return xgb_model


def train_logistic_regression(X_train, y_train):
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)
    return lr_model


def train_svm(X_train, y_train):
    svm_model = SVC(kernel='linear', random_state=42)
    svm_model.fit(X_train, y_train)
    return svm_model

def train_knn(X_train, y_train):
    knn_model = KNeighborsClassifier(n_neighbors=5)
    knn_model.fit(X_train, y_train)
    return knn_model

def train_lgb(X_train, y_train):
    lgb_model = lgb.LGBMClassifier()
    lgb_model.fit(X_train, y_train)
    return lgb_model

def train_pac(X_train, y_train):
    pac_model = PassiveAggressiveClassifier(max_iter=1000, random_state=42)
    pac_model.fit(X_train, y_train)
    return pac_model

# Evaluate and visualize
def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"üîπ {model_name} Accuracy: {acc:.4f}\n")
    print(f"üîπ Classification Report for {model_name}:")
    # Use all target names instead of just the first 5
    print(classification_report(y_test, y_pred, target_names=newsgroups_train.target_names))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, cmap='Blues', annot=False)
    plt.title(f"Confusion Matrix - {model_name}")
    plt.show()
    return acc

"""# **Train Models**"""

# Logistic regression
lr_model = train_logistic_regression(X_train_tfidf, y_train)
acc_lr = evaluate_model(lr_model, X_test_tfidf, y_test, "Logistic Regression")

# Naive Bayes
nb_model = train_naive_bayes(X_train_tfidf, y_train)
acc_nb = evaluate_model(nb_model, X_test_tfidf, y_test, "Naive Bayes")

# Support vector machine
svm_model = train_svm(X_train_tfidf, y_train)
acc_svm = evaluate_model(svm_model, X_test_tfidf, y_test, "Support Vector Machine")

# Random Forest
rf_model = train_random_forest(X_train_tfidf, y_train)
acc_rf = evaluate_model(rf_model, X_test_tfidf, y_test, "Random Forest")

# XGBoost
xgb_model = train_xgboost(X_train_tfidf, y_train)
acc_xgb = evaluate_model(xgb_model, X_test_tfidf, y_test, "XGBoost")

# KNN
knn_model = train_knn(X_train_tfidf, y_train)
acc_knn = evaluate_model(knn_model, X_test_tfidf, y_test, "KNN")

# LightGBM
lgb_model = train_lgb(X_train_tfidf, y_train)
acc_lgb = evaluate_model(lgb_model, X_test_tfidf, y_test, "LightGBM" )

# PAC
pac_model = train_pac(X_train_tfidf, y_train)
acc_pac = evaluate_model(pac_model, X_test_tfidf, y_test, "PAC" )

"""# **Performance**"""

model_names_extended = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forest', 'XGBoost', 'KNN', 'LightGBM ', 'PassiveAggressive']
accuracies_extended = [acc_lr, acc_nb, acc_svm, acc_rf, acc_xgb, acc_knn, acc_lgb, acc_pac]

plt.figure(figsize=(12,6))
sns.barplot(x=model_names_extended, y=accuracies_extended, palette='viridis')
plt.title("Extended Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.show()

plt.figure(figsize=(12,6))
ax = sns.barplot(x=model_names_extended, y=accuracies_extended, palette='viridis')

for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{height:.2%}',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='bottom',
                fontsize=11, color='black', xytext=(0, 8),
                textcoords='offset points')

plt.title("Extended Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.ylim(0, 1.05)
plt.show()

"""# **metrics**"""

models_extended = [lr_model, nb_model, svm_model, rf_model, xgb_model, knn_model, lgb_model, pac_model]

metrics_list = []

for model in models_extended:
    y_pred = model.predict(X_test_tfidf)
    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')
    metrics_list.append((precision, recall, f1))

metrics_df = pd.DataFrame(metrics_list, columns=['Precision', 'Recall', 'F1-score'])
metrics_df.insert(0, 'Model', model_names_extended)
metrics_df.insert(1, 'Accuracy', accuracies_extended)

print(metrics_df.round(4))

"""# **Tuning the hyperparameters of the best models**"""

param_grid_lr = {'C': [0.01, 0.1, 1, 10], 'max_iter': [500, 1000]}
grid_lr = GridSearchCV(LogisticRegression(random_state=42), param_grid_lr, cv=3, scoring='accuracy')
grid_lr.fit(X_train_tfidf, y_train)
best_lr = grid_lr.best_estimator_

param_grid_nb = {'alpha': [0.01, 0.1, 1, 5, 10]}
grid_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=3, scoring='accuracy')
grid_nb.fit(X_train_tfidf, y_train)
best_nb = grid_nb.best_estimator_

param_grid_pac = {'C': [0.01, 0.1, 1, 10], 'max_iter': [500, 1000]}
grid_pac = GridSearchCV(PassiveAggressiveClassifier(random_state=42), param_grid_pac, cv=3, scoring='accuracy')
grid_pac.fit(X_train_tfidf, y_train)
best_pac = grid_pac.best_estimator_

# Logistic Regression
y_pred_lr = best_lr.predict(X_test_tfidf)
acc_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr, average='weighted')
recall_lr = recall_score(y_test, y_pred_lr, average='weighted')
f1_lr = f1_score(y_test, y_pred_lr, average='weighted')

# Naive Bayes
y_pred_nb = best_nb.predict(X_test_tfidf)
acc_nb = accuracy_score(y_test, y_pred_nb)
precision_nb = precision_score(y_test, y_pred_nb, average='weighted')
recall_nb = recall_score(y_test, y_pred_nb, average='weighted')
f1_nb = f1_score(y_test, y_pred_nb, average='weighted')

#PassiveAggressiveClassifier
y_pred_pac = best_pac.predict(X_test_tfidf)
acc_pac = accuracy_score(y_test, y_pred_pac)
precision_pac = precision_score(y_test, y_pred_pac, average='weighted')
recall_pac = recall_score(y_test, y_pred_pac, average='weighted')
f1_pac = f1_score(y_test, y_pred_pac, average='weighted')

model_names = ['Logistic Regression', 'Naive Bayes', 'Passive Aggressive']
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']

scores = [
    [acc_lr, precision_lr, recall_lr, f1_lr],
    [acc_nb, precision_nb, recall_nb, f1_nb],
    [acc_pac, precision_pac, recall_pac, f1_pac]
]

df_scores = pd.DataFrame(scores, columns=metrics, index=model_names).reset_index()
df_scores = df_scores.melt(id_vars='index', var_name='Metric', value_name='Score')
df_scores.rename(columns={'index': 'Model'}, inplace=True)

plt.figure(figsize=(12, 6))
ax = sns.barplot(data=df_scores, x='Model', y='Score', hue='Metric', palette='Set2')
plt.ylim(0, 1.05)
plt.title("üîç Model Performance Comparison Across Metrics")
plt.ylabel("Score")
plt.xlabel("Model")
plt.legend(title="Metric")

for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{height:.4f}',
                (p.get_x() + p.get_width() / 4., height),
                ha='center', va='bottom',
                fontsize=10, color='black', xytext=(0, 4),
                textcoords='offset points')

plt.tight_layout()
plt.show()